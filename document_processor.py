"""
–û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è DocKitBot
"""

import os
import re
from collections import defaultdict
from typing import Any, Dict, List, Tuple

from loguru import logger

from config import Config
from file_handler import FileHandler
from image_processor import ImageProcessor
from pdf_converter import PDFConverter


class DocumentProcessor:
    def __init__(self):
        self.config = Config()
        self.image_processor = ImageProcessor()
        self.pdf_converter = PDFConverter()
        self.file_handler = FileHandler()

    async def process_single_file(self, file_path: str, user_id: int) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
            file_info = self.file_handler.get_file_info(file_path)
            if not file_info:
                return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ'}

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
            validation = self.file_handler.validate_file_name(
                file_info['name'])
            if not validation['valid']:
                return {
                    'success': False,
                    'error': f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞: {'; '.join(validation['warnings'])}"
                }

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
            processed_file = await self._process_file(file_path, file_info)

            if not processed_file:
                return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª'}

            # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤ —Å –æ–¥–Ω–∏–º —Ñ–∞–π–ª–æ–º
            archive_path = self.file_handler.create_archive(
                [processed_file], user_id)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å—å
            inventory = self._create_inventory([processed_file])

            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            self.file_handler.cleanup_user_files(user_id)

            return {
                'success': True,
                'archive_path': archive_path,
                'inventory': inventory,
                'errors': validation.get('warnings', [])
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return {'success': False, 'error': str(e)}

    async def process_multiple_files(self, file_paths: List[str], user_id: int) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤"""
        try:
            processed_files = []
            errors = []

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
            for file_path in file_paths:
                try:
                    file_info = self.file_handler.get_file_info(file_path)
                    if not file_info:
                        errors.append(
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ: {file_path}")
                        continue

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º—è —Ñ–∞–π–ª–∞
                    validation = self.file_handler.validate_file_name(
                        file_info['name'])
                    if validation['warnings']:
                        errors.extend(validation['warnings'])

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
                    processed_file = await self._process_file(file_path, file_info)
                    if processed_file:
                        processed_files.append(processed_file)
                    else:
                        errors.append(
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª: {file_info['name']}")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
                    errors.append(
                        f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {os.path.basename(file_path)}: {str(e)}")

            if not processed_files:
                return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞'}

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            final_files = await self._group_and_merge_pages(processed_files)

            # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤
            archive_path = self.file_handler.create_archive(
                final_files, user_id)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ–ø–∏—Å—å
            inventory = self._create_inventory(final_files)

            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            self.file_handler.cleanup_user_files(user_id)

            return {
                'success': True,
                'archive_path': archive_path,
                'inventory': inventory,
                'errors': errors
            }

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
            return {'success': False, 'error': str(e)}

    async def _process_file(self, file_path: str, file_info: Dict[str, Any]) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª (–ø–æ–≤–æ—Ä–æ—Ç, –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è)"""
        try:
            file_ext = file_info['extension']

            # –ï—Å–ª–∏ —ç—Ç–æ PDF, –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º
            if file_ext == '.pdf':
                return file_path

            # –ï—Å–ª–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
            if file_ext in self.config.SUPPORTED_IMAGE_FORMATS:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—é
                corrected_image = await self.image_processor.correct_orientation(file_path)

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PDF
                pdf_path = await self.pdf_converter.image_to_pdf(corrected_image, file_info['name'])

                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                if corrected_image != file_path:
                    os.remove(corrected_image)

                return pdf_path

            return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return None

    async def _group_and_merge_pages(self, processed_files: List[str]) -> List[str]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –º–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã"""
        try:
            logger.info(f"–ù–∞—á–∏–Ω–∞—é –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É {len(processed_files)} —Ñ–∞–π–ª–æ–≤")

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –±–∞–∑–æ–≤–æ–º—É –∏–º–µ–Ω–∏
            file_groups = defaultdict(list)

            for file_path in processed_files:
                file_name = os.path.basename(file_path)
                base_name, page_info = self._extract_base_name_and_page(
                    file_name)
                logger.info(
                    f"–§–∞–π–ª: {file_name} -> –±–∞–∑–æ–≤–æ–µ –∏–º—è: '{base_name}', —Å—Ç—Ä–∞–Ω–∏—Ü–∞: {page_info}")
                file_groups[base_name].append((file_path, page_info))

            logger.info(f"–ù–∞–π–¥–µ–Ω–æ –≥—Ä—É–ø–ø: {len(file_groups)}")
            for base_name, files in file_groups.items():
                logger.info(f"–ì—Ä—É–ø–ø–∞ '{base_name}': {len(files)} —Ñ–∞–π–ª–æ–≤")

            final_files = []

            for base_name, files_with_pages in file_groups.items():
                if len(files_with_pages) == 1:
                    # –û–¥–Ω–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
                    logger.info(f"–û–¥–Ω–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {base_name}")
                    final_files.append(files_with_pages[0][0])
                else:
                    # –ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
                    logger.info(
                        f"–ú–Ω–æ–≥–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç: {base_name}, —Ñ–∞–π–ª–æ–≤: {len(files_with_pages)}")
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    sorted_files = sorted(
                        files_with_pages, key=lambda x: x[1] if x[1] else 0)

                    logger.info(f"–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è {base_name}:")
                    for file_path, page_num in sorted_files:
                        logger.info(
                            f"  –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: {os.path.basename(file_path)}")

                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω PDF
                    file_paths = [f[0] for f in sorted_files]
                    merged_pdf = await self.pdf_converter.merge_pdfs(file_paths, base_name)

                    if merged_pdf:
                        logger.info(f"PDF –æ–±—ä–µ–¥–∏–Ω–µ–Ω: {merged_pdf}")
                        final_files.append(merged_pdf)
                    else:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å, –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏
                        logger.warning(
                            f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å PDF –¥–ª—è {base_name}")
                        final_files.extend(file_paths)

            logger.info(f"–ò—Ç–æ–≥–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {len(final_files)}")
            return final_files

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ —Ñ–∞–π–ª–æ–≤: {e}")
            return processed_files

    def _extract_base_name_and_page(self, file_name: str) -> Tuple[str, int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤–æ–µ –∏–º—è –∏ –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        name_without_ext = os.path.splitext(file_name)[0]
        logger.info(f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏–º—è —Ñ–∞–π–ª–∞: '{name_without_ext}'")

        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Ç—Ä–∞–Ω–∏—Ü
        for pattern in self.config.PAGE_PATTERNS:
            match = re.search(pattern, name_without_ext, re.IGNORECASE)
            if match:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_text = match.group()
                page_number = re.search(r'\d+', page_text)
                if page_number:
                    page_num = int(page_number.group())
                    # –£–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏–∑ –∏–º–µ–Ω–∏
                    base_name = re.sub(
                        pattern, '', name_without_ext, flags=re.IGNORECASE).strip()
                    logger.info(
                        f"–ù–∞–π–¥–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω '{pattern}': —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}, –±–∞–∑–æ–≤–æ–µ –∏–º—è: '{base_name}'")
                    return base_name, page_num

        # –ï—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –±–∞–∑–æ–≤–æ–µ –∏–º—è: '{name_without_ext}'")
        return name_without_ext, None

    def _create_inventory(self, files: List[str]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ–ø–∏—Å—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        inventory = "üìã **–û–ø–∏—Å—å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**\n\n"

        for i, file_path in enumerate(files, 1):
            file_name = os.path.basename(file_path)
            # –£–±–∏—Ä–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            display_name = os.path.splitext(file_name)[0]
            inventory += f"{i}. {display_name}.pdf\n"

        return inventory
